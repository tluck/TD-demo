{\rtf1\ansi\ansicpg1252\cocoartf1671\cocoasubrtf200
{\fonttbl\f0\fnil\fcharset0 Menlo-Bold;\f1\fnil\fcharset0 Menlo-Regular;}
{\colortbl;\red255\green255\blue255;\red79\green218\blue57;\red65\green65\blue65;\red194\green194\blue54;
\red255\green255\blue255;}
{\*\expandedcolortbl;;\cssrgb\c35880\c86584\c28379;\csgenericrgb\c25299\c25299\c25299\c90000;\cssrgb\c80507\c79484\c26958;
\csgenericrgb\c100000\c100000\c100000;}
\margl1440\margr1440\vieww29500\viewh11980\viewkind0
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\f0\b\fs22 \cf2 \cb3 \CocoaLigature0 tluck@Toms-MB \cf4 ~/treasure-data/TD-demo/sample_data
\f1\b0 \cf5 \
$ ./my_database_load.bash \
converting from CSV to JSON\
Loading JSON to evaluation_thomasluckenbach into sales_data\
Account is already configured.\
Add '-f' option to overwrite.\
Table 'evaluation_thomasluckenbach.sales_data' is created.\
importing sales_data.json...\
  imported 10000 entries from sales_data.json...\
  imported 20000 entries from sales_data.json...\
  imported 30000 entries from sales_data.json...\
  imported 40000 entries from sales_data.json...\
  imported 50000 entries from sales_data.json...\
  imported 60000 entries from sales_data.json...\
  imported 70000 entries from sales_data.json...\
  imported 80000 entries from sales_data.json...\
  imported 90000 entries from sales_data.json...\
  imported 100000 entries from sales_data.json...\
  imported 110000 entries from sales_data.json...\
  imported 120000 entries from sales_data.json...\
  imported 130000 entries from sales_data.json...\
  imported 140000 entries from sales_data.json...\
  imported 141021 entries from sales_data.json...\
  uploading 1059850 bytes...\
  imported 150000 entries from sales_data.json...\
  imported 160000 entries from sales_data.json...\
  imported 170000 entries from sales_data.json...\
  imported 180000 entries from sales_data.json...\
  imported 190000 entries from sales_data.json...\
  imported 200000 entries from sales_data.json...\
  imported 210000 entries from sales_data.json...\
  imported 220000 entries from sales_data.json...\
  imported 230000 entries from sales_data.json...\
  imported 240000 entries from sales_data.json...\
  imported 250000 entries from sales_data.json...\
  imported 260000 entries from sales_data.json...\
  imported 270000 entries from sales_data.json...\
  imported 280000 entries from sales_data.json...\
  imported 286724 entries from sales_data.json...\
  uploading 1069724 bytes...\
  imported 290000 entries from sales_data.json...\
  imported 300000 entries from sales_data.json...\
  imported 310000 entries from sales_data.json...\
  imported 320000 entries from sales_data.json...\
  imported 330000 entries from sales_data.json...\
  imported 340000 entries from sales_data.json...\
  imported 350000 entries from sales_data.json...\
  imported 360000 entries from sales_data.json...\
  imported 370000 entries from sales_data.json...\
  imported 380000 entries from sales_data.json...\
  imported 390000 entries from sales_data.json...\
  imported 400000 entries from sales_data.json...\
  imported 410000 entries from sales_data.json...\
  imported 420000 entries from sales_data.json...\
  imported 427886 entries from sales_data.json...\
  uploading 1049269 bytes...\
  imported 430000 entries from sales_data.json...\
  imported 440000 entries from sales_data.json...\
  imported 450000 entries from sales_data.json...\
  imported 460000 entries from sales_data.json...\
  imported 470000 entries from sales_data.json...\
  imported 480000 entries from sales_data.json...\
  imported 490000 entries from sales_data.json...\
  imported 500000 entries from sales_data.json...\
  imported 510000 entries from sales_data.json...\
  imported 520000 entries from sales_data.json...\
  imported 530000 entries from sales_data.json...\
  imported 540000 entries from sales_data.json...\
  imported 550000 entries from sales_data.json...\
  imported 560000 entries from sales_data.json...\
  imported 570000 entries from sales_data.json...\
  imported 570729 entries from sales_data.json...\
  uploading 1048695 bytes...\
  imported 580000 entries from sales_data.json...\
  imported 590000 entries from sales_data.json...\
  imported 600000 entries from sales_data.json...\
  imported 610000 entries from sales_data.json...\
  imported 620000 entries from sales_data.json...\
  imported 630000 entries from sales_data.json...\
  imported 640000 entries from sales_data.json...\
  imported 650000 entries from sales_data.json...\
  imported 660000 entries from sales_data.json...\
  imported 670000 entries from sales_data.json...\
  imported 680000 entries from sales_data.json...\
  imported 690000 entries from sales_data.json...\
  imported 700000 entries from sales_data.json...\
  imported 710000 entries from sales_data.json...\
  imported 717176 entries from sales_data.json...\
  uploading 1056316 bytes...\
  imported 720000 entries from sales_data.json...\
  imported 730000 entries from sales_data.json...\
  imported 740000 entries from sales_data.json...\
  imported 750000 entries from sales_data.json...\
  imported 760000 entries from sales_data.json...\
  imported 770000 entries from sales_data.json...\
  imported 780000 entries from sales_data.json...\
  imported 790000 entries from sales_data.json...\
  imported 800000 entries from sales_data.json...\
  imported 810000 entries from sales_data.json...\
  imported 820000 entries from sales_data.json...\
  imported 830000 entries from sales_data.json...\
  imported 840000 entries from sales_data.json...\
  imported 847184 entries from sales_data.json...\
  uploading 1053764 bytes...\
  imported 850000 entries from sales_data.json...\
  imported 860000 entries from sales_data.json...\
  imported 870000 entries from sales_data.json...\
  imported 880000 entries from sales_data.json...\
  imported 890000 entries from sales_data.json...\
  imported 900000 entries from sales_data.json...\
  imported 910000 entries from sales_data.json...\
  uploading 564813 bytes...\
  imported 916039 entries from sales_data.json.\
done.\
Show table details of my database evaluation_thomasluckenbach\
Waiting for data to be processed\
+---------------+------+--------+--------------------------------------------------------------------------------------+\
| Table         | Type | Count  | Schema                                                                               |\
+---------------+------+--------+--------------------------------------------------------------------------------------+\
| customer_data | log  | 0      | id:int, zip:long, phone:string, last:string, status:string, street:string, city:s... |\
| sales_data    | log  | 916039 | amount:double, promo_id:long, unit_cost:double, prod_id:long, quantity:long, date... |\
+---------------+------+--------+--------------------------------------------------------------------------------------+\
2 rows in set\
\
\
\
\
\

\f0\b \cf2 tluck@Toms-MB \cf4 ~/treasure-data/TD-demo
\f1\b0 \cf5 \
$ ./my_database_query.bash \
\
Using DB: evaluation_thomasluckenbach to Query table: sales_data \
The query of value entered of column: prod_id \
 and will calculate the count and sum of column: amount \
\
Show table \
Name        : evaluation_thomasluckenbach.sales_data\
Type        : log\
Count       : 916039\
Schema      : (\
    amount:double\
    promo_id:long\
    unit_cost:double\
    prod_id:long\
    quantity:long\
    date:string\
    unit_price:double\
    cust_id:long\
    channel_id:long\
)\
\
Determining valid list items ... Done\
\
Determine Time Range for table: sales_data ... Done\
The Min Date        and Max Date\
1998-01-10 23:56:00	1998-01-21 14:23:18\
\
\
Enter a Value to query - or zero to quit: 13\
\
Getting cumulative data for prod_id=13 ... For a total number of 6002 transactions, the Sales Revenue = $ 6312268.40 \
\
\
Enter a Value to query - or zero to quit: 12\
\
\
 Try again - Enter a valid value for prod_id \
\
\
Enter a Value to query - or zero to quit: 14\
\
Getting cumulative data for prod_id=14 ... For a total number of 6010 transactions, the Sales Revenue = $ 7189171.77 \
\
\
Enter a Value to query - or zero to quit: 0\
\
\
\

\f0\b \cf2 tluck@Toms-MB \cf4 ~/treasure-data/TD-demo
\f1\b0 \cf5 \
$ ./my_database_query.bash x\
Enter table name to query:x\
Database 'x' does not exist\
Use 'td database:list' to show the list of databases.\
**** Error on accessing DB x\
\
$ vi my_database_query.bash \
\

\f0\b \cf2 tluck@Toms-MB \cf4 ~/treasure-data/TD-demo
\f1\b0 \cf5 \
$ ./my_database_query.bash evaluation_thomasluckenbach\
+---------------+------+--------+--------------------------------------------------------------------------------------+\
| Table         | Type | Count  | Schema                                                                               |\
+---------------+------+--------+--------------------------------------------------------------------------------------+\
| customer_data | log  | 0      | id:int, zip:long, phone:string, last:string, status:string, street:string, city:s... |\
| sales_data    | log  | 916039 | amount:double, promo_id:long, unit_cost:double, prod_id:long, quantity:long, date... |\
+---------------+------+--------+--------------------------------------------------------------------------------------+\
2 rows in set\
Enter table name to query:sales_data \
\
Using DB: evaluation_thomasluckenbach to Query table: sales_data \
\
Enter column name to sum results of query: quantity\
Enter column name for the query predicate: prod_id\
The query of value entered of column: prod_id \
and will calculate the count and sum of column: quantity \
\
Show table \
Name        : evaluation_thomasluckenbach.sales_data\
Type        : log\
Count       : 916039\
Schema      : (\
    amount:double\
    promo_id:long\
    unit_cost:double\
    prod_id:long\
    quantity:long\
    date:string\
    unit_price:double\
    cust_id:long\
    channel_id:long\
)\
\
Determining valid list items ... Done\
\
Determine Time Range for table: sales_data ... Done\
The Min Date        and Max Date\
1998-01-10 23:56:00	1998-01-21 14:23:18\
\
\
Enter a Value to query - or zero to quit: 13\
\
Getting cumulative data for prod_id=13 ... For a total number of 6002 transactions, the sum of the query column =     6002.00 \
\
\
Enter a Value to query - or zero to quit: 12\
\
\
 Try again - Enter a valid value for prod_id \
\
\
Enter a Value to query - or zero to quit: 0\
\

\f0\b \cf2 tluck@Toms-MB \cf4 ~/treasure-data/TD-demo
\f1\b0 \cf5 \
\
}